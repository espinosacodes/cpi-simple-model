{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Made by: Santiago Espinosa Giraldo\n",
        "\n",
        "https://github.com/espinosacodes\n",
        "\n",
        "\n",
        "https://www.linkedin.com/in/santiago-espinosa-a80a43287/"
      ],
      "metadata": {
        "id": "6bDS28XxGm76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Description:\n",
        "\n",
        "The model is designed to trade financial data, specifically focusing on the Consumer Price Index (CPI) as it impacts stocks listed on NASDAQ. The core functionality involves analyzing historical CPI data alongside other market indicators to predict future movements. The model leverages machine learning algorithms to identify patterns and trends in the data that can inform trading decisions.\n",
        "\n",
        "# Objective:\n",
        "\n",
        "The primary goal is to achieve a competitive edge in trading by accurately predicting market movements based on CPI data, thereby maximizing profits while minimizing risks.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a1HPP2yvxEW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **in this section there is importing data from 2010 hourly between london seccion**"
      ],
      "metadata": {
        "id": "aUa7JZ4XGY-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pytz\n",
        "\n",
        "# Define the ticker for NASDAQ\n",
        "ticker = \"^IXIC\"\n",
        "\n",
        "# Download the data in 1-hour intervals\n",
        "data = yf.download(ticker, start=\"2024-01-01\", end=\"2024-06-09\", interval=\"1h\")\n",
        "\n",
        "# Convert the timezone of the data's index to \"America/New_York\"\n",
        "data.index = data.index.tz_convert(\"America/New_York\")\n",
        "\n",
        "# Assume CPI releases on the second Tuesday of each month at 8:30 AM ET\n",
        "cpi_release_dates = [\n",
        "    \"2024-01-09 08:30:00\",\n",
        "    \"2024-02-13 08:30:00\",\n",
        "    \"2024-03-12 08:30:00\",\n",
        "    \"2024-04-09 08:30:00\",\n",
        "    \"2024-05-14 08:30:00\",\n",
        "    \"2024-06-11 08:30:00\"\n",
        "]\n",
        "\n",
        "# Convert strings to pandas datetime objects and make them timezone-aware\n",
        "cpi_release_dates = pd.to_datetime(cpi_release_dates).tz_localize(\"America/New_York\")\n",
        "\n",
        "# Filter data to include only 1 hour before and after the CPI release\n",
        "filtered_data = pd.concat([data.loc[(data.index >= date - pd.Timedelta(hours=1)) &\n",
        "                                    (data.index <= date + pd.Timedelta(hours=1))]\n",
        "                           for date in cpi_release_dates])\n",
        "\n",
        "print(filtered_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIWob6xECSxE",
        "outputId": "f64cd26c-4eee-43ce-d733-a201b025fed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                   Open          High           Low  \\\n",
            "Datetime                                                              \n",
            "2024-01-09 09:30:00-05:00  14741.954102  14789.148438  14716.916016   \n",
            "2024-02-13 09:30:00-05:00  15604.243164  15725.561523  15591.212891   \n",
            "2024-03-12 09:30:00-04:00  16121.386719  16169.294922  15994.012695   \n",
            "2024-04-09 09:30:00-04:00  16330.896484  16347.339844  16247.916992   \n",
            "2024-05-14 09:30:00-04:00  16388.925781  16465.736328  16388.804688   \n",
            "\n",
            "                                  Close     Adj Close  Volume  \n",
            "Datetime                                                       \n",
            "2024-01-09 09:30:00-05:00  14769.126953  14769.126953       0  \n",
            "2024-02-13 09:30:00-05:00  15725.561523  15725.561523       0  \n",
            "2024-03-12 09:30:00-04:00  16169.294922  16169.294922       0  \n",
            "2024-04-09 09:30:00-04:00  16249.747070  16249.747070       0  \n",
            "2024-05-14 09:30:00-04:00  16462.855469  16462.855469       0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the asset data is loaded in that period of time"
      ],
      "metadata": {
        "id": "my9djfG3UXzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data"
      ],
      "metadata": {
        "id": "ssiJaOW7JY6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "e85c9117-b283-425c-c726-b7d3494f34a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Open          High           Low  \\\n",
              "Datetime                                                              \n",
              "2024-01-09 09:30:00-05:00  14741.954102  14789.148438  14716.916016   \n",
              "2024-02-13 09:30:00-05:00  15604.243164  15725.561523  15591.212891   \n",
              "2024-03-12 09:30:00-04:00  16121.386719  16169.294922  15994.012695   \n",
              "2024-04-09 09:30:00-04:00  16330.896484  16347.339844  16247.916992   \n",
              "2024-05-14 09:30:00-04:00  16388.925781  16465.736328  16388.804688   \n",
              "\n",
              "                                  Close     Adj Close  Volume  \n",
              "Datetime                                                       \n",
              "2024-01-09 09:30:00-05:00  14769.126953  14769.126953       0  \n",
              "2024-02-13 09:30:00-05:00  15725.561523  15725.561523       0  \n",
              "2024-03-12 09:30:00-04:00  16169.294922  16169.294922       0  \n",
              "2024-04-09 09:30:00-04:00  16249.747070  16249.747070       0  \n",
              "2024-05-14 09:30:00-04:00  16462.855469  16462.855469       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f85803d-38f5-4dc0-8cbb-6b4fd78f9361\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2024-01-09 09:30:00-05:00</th>\n",
              "      <td>14741.954102</td>\n",
              "      <td>14789.148438</td>\n",
              "      <td>14716.916016</td>\n",
              "      <td>14769.126953</td>\n",
              "      <td>14769.126953</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-13 09:30:00-05:00</th>\n",
              "      <td>15604.243164</td>\n",
              "      <td>15725.561523</td>\n",
              "      <td>15591.212891</td>\n",
              "      <td>15725.561523</td>\n",
              "      <td>15725.561523</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-12 09:30:00-04:00</th>\n",
              "      <td>16121.386719</td>\n",
              "      <td>16169.294922</td>\n",
              "      <td>15994.012695</td>\n",
              "      <td>16169.294922</td>\n",
              "      <td>16169.294922</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-04-09 09:30:00-04:00</th>\n",
              "      <td>16330.896484</td>\n",
              "      <td>16347.339844</td>\n",
              "      <td>16247.916992</td>\n",
              "      <td>16249.747070</td>\n",
              "      <td>16249.747070</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-14 09:30:00-04:00</th>\n",
              "      <td>16388.925781</td>\n",
              "      <td>16465.736328</td>\n",
              "      <td>16388.804688</td>\n",
              "      <td>16462.855469</td>\n",
              "      <td>16462.855469</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f85803d-38f5-4dc0-8cbb-6b4fd78f9361')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f85803d-38f5-4dc0-8cbb-6b4fd78f9361 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f85803d-38f5-4dc0-8cbb-6b4fd78f9361');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b099104d-0229-4cf4-8f26-3a587b062a98\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b099104d-0229-4cf4-8f26-3a587b062a98')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b099104d-0229-4cf4-8f26-3a587b062a98 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_86e17b18-28c3-4ede-994b-b0d443775d37\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('filtered_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_86e17b18-28c3-4ede-994b-b0d443775d37 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('filtered_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "filtered_data",
              "summary": "{\n  \"name\": \"filtered_data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-01-09 09:30:00-05:00\",\n        \"max\": \"2024-05-14 09:30:00-04:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2024-02-13 09:30:00-05:00\",\n          \"2024-05-14 09:30:00-04:00\",\n          \"2024-03-12 09:30:00-04:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 686.0633566662074,\n        \"min\": 14741.9541015625,\n        \"max\": 16388.92578125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          15604.2431640625,\n          16388.92578125,\n          16121.38671875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 681.3788512421127,\n        \"min\": 14789.1484375,\n        \"max\": 16465.736328125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          15725.5615234375,\n          16465.736328125,\n          16169.294921875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 670.9837837886957,\n        \"min\": 14716.916015625,\n        \"max\": 16388.8046875,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          15591.212890625,\n          16388.8046875,\n          15994.0126953125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 674.1486243646245,\n        \"min\": 14769.126953125,\n        \"max\": 16462.85546875,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          15725.5615234375,\n          16462.85546875,\n          16169.294921875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 674.1486243646245,\n        \"min\": 14769.126953125,\n        \"max\": 16462.85546875,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          15725.5615234375,\n          16462.85546875,\n          16169.294921875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Data Collection:\n",
        "Gather historical data for CPI, Initial Jobless Claims, Nonfarm Payrolls, Jobless Claims, and Crude Oil Inventories.\n",
        "Align the data to ensure that all series have the same frequency (e.g., daily or weekly) and are aligned on the same dates.\n",
        "##2. Data Preprocessing:\n",
        "Handle missing values, normalize/scale the data, and create lag features if necessary.\n",
        "##3. Feature Engineering:\n",
        "Create new features based on existing data, such as moving averages, percentage changes, or other relevant indicators.\n",
        "##4. Model Training:\n",
        "Train a machine learning model (e.g., Random Forest, Gradient Boosting, or a Neural Network) using the engineered features to predict future CPI movements.\n",
        "##5. Generating Buy/Sell Signals:\n",
        "Use the model's predictions to generate buy or sell signals based on the predicted direction of CPI movements."
      ],
      "metadata": {
        "id": "Tq0sMmIv7NgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this cell to install the fredapi package:"
      ],
      "metadata": {
        "id": "WAd55cdo8YlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fredapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02v7capU8UJV",
        "outputId": "809281e9-ff5e-4834-e94e-d99361804a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fredapi in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fredapi) (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->fredapi) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas_datareader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPRZQyrkYW_T",
        "outputId": "017a9278-0951-4075-a0aa-9d0811b3d17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas_datareader in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pandas_datareader) (4.9.4)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.10/dist-packages (from pandas_datareader) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pandas_datareader) (2.32.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas_datareader) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas_datareader) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas_datareader) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas_datareader) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas_datareader) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas_datareader) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas_datareader) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas_datareader) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.23->pandas_datareader) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Assuming cpi, initial_jobless_claims, nonfarm_payrolls, and crude_oil_prices\n",
        "# are already loaded as DataFrames from the FRED API or another source\n",
        "\n",
        "# Rename columns to a consistent format\n",
        "cpi.rename(columns={'CPIAUCNS': 'CPI'}, inplace=True)\n",
        "initial_jobless_claims.rename(columns={'ICSA': 'Initial Jobless Claims'}, inplace=True)\n",
        "nonfarm_payrolls.rename(columns={'PAYNSA': 'Nonfarm Payrolls'}, inplace=True)\n",
        "crude_oil_prices.rename(columns={'IR14200': 'Crude Oil Prices'}, inplace=True)\n",
        "\n",
        "# Ensure 'date' column is in datetime format and exists\n",
        "cpi['date'] = pd.to_datetime(cpi['date'])\n",
        "initial_jobless_claims['date'] = pd.to_datetime(initial_jobless_claims['date'])\n",
        "nonfarm_payrolls['date'] = pd.to_datetime(nonfarm_payrolls['date'])\n",
        "crude_oil_prices['date'] = pd.to_datetime(crude_oil_prices['date'])\n",
        "\n",
        "# Merge datasets with CPI as the base\n",
        "data = pd.merge(cpi, initial_jobless_claims, on='date', how='left')\n",
        "data = pd.merge(data, nonfarm_payrolls, on='date', how='left')\n",
        "data = pd.merge(data, crude_oil_prices, on='date', how='left')\n",
        "\n",
        "# Handle missing values\n",
        "data.ffill(inplace=True)  # Forward fill missing values\n",
        "\n",
        "# Feature Engineering: create lagged features\n",
        "data['CPI_Lag1'] = data['CPI'].shift(1)\n",
        "data['CPI_Lag2'] = data['CPI'].shift(2)\n",
        "data.dropna(inplace=True)  # Drop rows with NaN values after shifting\n",
        "\n",
        "# Define features and target\n",
        "features = ['CPI_Lag1', 'CPI_Lag2', 'Initial Jobless Claims', 'Nonfarm Payrolls', 'Crude Oil Prices']\n",
        "target = 'CPI'\n",
        "\n",
        "# Split the data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "# Predict the next CPI value\n",
        "latest_data = data.iloc[-1][features].to_frame().T  # Use the most recent data row with correct column names\n",
        "next_cpi_prediction = model.predict(latest_data)\n",
        "\n",
        "print(f\"Predicted Next CPI Value: {next_cpi_prediction[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktIE-4lRCcbT",
        "outputId": "9f22ed75-c89f-4fc2-ede2-c0832203de42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 3647.9153050763052\n",
            "Predicted Next CPI Value: 3.6971095208765377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclutions\n",
        "\n",
        "\n",
        "\n",
        "Model Performance:\n",
        "\n",
        "Mean Squared Error (MSE): An MSE of approximately 3647.92 indicates the average squared difference between the predicted and actual CPI values on the test set. While there's no benchmark MSE to definitively judge the performance without context, a high MSE suggests that the model might not be very accurate in predicting CPI values. The higher the MSE, the larger the average prediction error, which could imply the model is not capturing the underlying patterns well.\n",
        "Predicted CPI Value:\n",
        "\n",
        "Predicted Next CPI Value: The model predicts a CPI value of approximately 3.70 for the next period. This value is an estimate based on the most recent data and the model’s understanding of the relationship between CPI and other features in the dataset.\n",
        "Implications for Decision-Making:\n",
        "\n",
        "Accuracy: Given the high MSE, there may be substantial variability or noise in the CPI predictions. This suggests that the model might be overfitting or underfitting the data, or that important features or interactions are missing.\n",
        "Model Improvement: To improve accuracy, consider:\n",
        "Feature Engineering: Adding more relevant features or exploring interactions between features.\n",
        "Model Complexity: Trying more complex models such as polynomial regression, decision trees, or ensemble methods.\n",
        "Data Quality: Ensuring that the data is comprehensive and accurately reflects all relevant aspects influencing CPI.\n",
        "Trading Decisions:\n",
        "\n",
        "Predicted CPI: If using this model to inform trading decisions, it’s important to be cautious due to the high MSE. Decisions based solely on this prediction might be risky. Incorporate additional analyses or models to validate trading signals and mitigate potential losses."
      ],
      "metadata": {
        "id": "ZeoA1p_RDoDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict the last CPI value without using the most recent CPI value."
      ],
      "metadata": {
        "id": "TPtMe9W3Djak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Ensure 'date' column is in datetime format\n",
        "cpi['date'] = pd.to_datetime(cpi['date'])\n",
        "initial_jobless_claims['date'] = pd.to_datetime(initial_jobless_claims['date'])\n",
        "nonfarm_payrolls['date'] = pd.to_datetime(nonfarm_payrolls['date'])\n",
        "crude_oil_prices['date'] = pd.to_datetime(crude_oil_prices['date'])\n",
        "\n",
        "# Merge datasets with CPI as the base\n",
        "data = pd.merge(cpi, initial_jobless_claims, on='date', how='left')\n",
        "data = pd.merge(data, nonfarm_payrolls, on='date', how='left')\n",
        "data = pd.merge(data, crude_oil_prices, on='date', how='left')\n",
        "\n",
        "# Handle missing values\n",
        "data.ffill(inplace=True)  # Forward fill missing values\n",
        "\n",
        "# Feature Engineering: create lagged features\n",
        "data['CPI_Lag1'] = data['CPI'].shift(1)\n",
        "data['CPI_Lag2'] = data['CPI'].shift(2)\n",
        "data.dropna(inplace=True)  # Drop rows with NaN values after shifting\n",
        "\n",
        "# Split the data to exclude the last CPI value for testing\n",
        "train_data = data.iloc[:-1]  # All rows except the last one for training\n",
        "test_data = data.iloc[-1:]   # Only the last row for testing\n",
        "\n",
        "# Define features and target\n",
        "features = ['CPI_Lag1', 'CPI_Lag2', 'Initial Jobless Claims', 'Nonfarm Payrolls', 'Crude Oil Prices']\n",
        "target = 'CPI'\n",
        "\n",
        "# Prepare training and testing data\n",
        "X_train = train_data[features]\n",
        "y_train = train_data[target]\n",
        "X_test = test_data[features]\n",
        "y_test = test_data[target]\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the CPI value of the last row\n",
        "next_cpi_prediction = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error only if there's test data for evaluation\n",
        "if not y_test.empty:\n",
        "    y_pred = model.predict(X_train)\n",
        "    mse = mean_squared_error(y_train, y_pred)\n",
        "    print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "print(f\"Predicted Last CPI Value: {next_cpi_prediction[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR3-JC9tDihO",
        "outputId": "bcf585d1-b278-452f-c6cb-9af94d67e765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.2590633799908734\n",
            "Predicted Last CPI Value: 313.5880483097469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#adding paramethers to take a long or short on nasdaq"
      ],
      "metadata": {
        "id": "PgpFaId3Di47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Example data loading, replace with actual loading mechanism\n",
        "# For demonstration, creating DataFrames with sample data\n",
        "# Replace these lines with actual data loading\n",
        "cpi = pd.DataFrame({\n",
        "    'date': pd.date_range(start='2020-01-01', periods=10, freq='M'),\n",
        "    'CPIAUCNS': np.random.rand(10) * 100\n",
        "})\n",
        "initial_jobless_claims = pd.DataFrame({\n",
        "    'date': pd.date_range(start='2020-01-01', periods=10, freq='M'),\n",
        "    'ICSA': np.random.rand(10) * 1000\n",
        "})\n",
        "nonfarm_payrolls = pd.DataFrame({\n",
        "    'date': pd.date_range(start='2020-01-01', periods=10, freq='M'),\n",
        "    'PAYNSA': np.random.rand(10) * 5000\n",
        "})\n",
        "crude_oil_prices = pd.DataFrame({\n",
        "    'date': pd.date_range(start='2020-01-01', periods=10, freq='M'),\n",
        "    'IR14200': np.random.rand(10) * 80\n",
        "})\n",
        "\n",
        "# Rename columns to a common format\n",
        "cpi.rename(columns={'CPIAUCNS': 'CPI'}, inplace=True)\n",
        "initial_jobless_claims.rename(columns={'ICSA': 'Initial Jobless Claims'}, inplace=True)\n",
        "nonfarm_payrolls.rename(columns={'PAYNSA': 'Nonfarm Payrolls'}, inplace=True)\n",
        "crude_oil_prices.rename(columns={'IR14200': 'Crude Oil Prices'}, inplace=True)\n",
        "\n",
        "# Ensure 'date' column is in datetime format\n",
        "cpi['date'] = pd.to_datetime(cpi['date'])\n",
        "initial_jobless_claims['date'] = pd.to_datetime(initial_jobless_claims['date'])\n",
        "nonfarm_payrolls['date'] = pd.to_datetime(nonfarm_payrolls['date'])\n",
        "crude_oil_prices['date'] = pd.to_datetime(crude_oil_prices['date'])\n",
        "\n",
        "# Merge datasets with CPI as the base\n",
        "data = pd.merge(cpi, initial_jobless_claims, on='date', how='left')\n",
        "data = pd.merge(data, nonfarm_payrolls, on='date', how='left')\n",
        "data = pd.merge(data, crude_oil_prices, on='date', how='left')\n",
        "\n",
        "# Handle missing values\n",
        "data.ffill(inplace=True)  # Forward fill missing values\n",
        "\n",
        "# Feature Engineering: create lagged features\n",
        "data['CPI_Lag1'] = data['CPI'].shift(1)\n",
        "data['CPI_Lag2'] = data['CPI'].shift(2)\n",
        "data.dropna(inplace=True)  # Drop rows with NaN values after shifting\n",
        "\n",
        "# Split the data to exclude the last CPI value for testing\n",
        "train_data = data.iloc[:-1]  # All rows except the last one for training\n",
        "test_data = data.iloc[-1:]   # Only the last row for testing\n",
        "\n",
        "# Define features and target\n",
        "features = ['CPI_Lag1', 'CPI_Lag2', 'Initial Jobless Claims', 'Nonfarm Payrolls', 'Crude Oil Prices']\n",
        "target = 'CPI'\n",
        "\n",
        "# Prepare training and testing data\n",
        "X_train = train_data[features]\n",
        "y_train = train_data[target]\n",
        "X_test = test_data[features]\n",
        "y_test = test_data[target]\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the CPI value of the last row\n",
        "next_cpi_prediction = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error only if there's enough test data for evaluation\n",
        "if len(X_train) > 0:\n",
        "    y_pred = model.predict(X_train)\n",
        "    mse = mean_squared_error(y_train, y_pred)\n",
        "    print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "print(f\"Predicted Last CPI Value: {next_cpi_prediction[0]}\")\n",
        "\n",
        "# Trading Logic based on CPI prediction\n",
        "current_cpi_value = data['CPI'].iloc[-1]  # Last observed CPI value\n",
        "\n",
        "# Example trading logic\n",
        "if next_cpi_prediction[0] > current_cpi_value:\n",
        "    position = 'Long'  # Buy\n",
        "    action = 'Buy NASDAQ'\n",
        "elif next_cpi_prediction[0] < current_cpi_value:\n",
        "    position = 'Short'  # Sell\n",
        "    action = 'Sell NASDAQ'\n",
        "else:\n",
        "    position = 'Hold'  # No change\n",
        "    action = 'Hold NASDAQ'\n",
        "\n",
        "print(f\"Trading Position: {position}\")\n",
        "print(f\"Action: {action}\")\n",
        "\n",
        "# For actual trading, you would integrate with a trading platform or API\n",
        "# Here, we are only simulating the decision-making process\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYxdFNGuEIDS",
        "outputId": "12aa8c19-c3d3-4fb8-e439-9cc903dbd314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 104.73815055081666\n",
            "Predicted Last CPI Value: 13.790251019439395\n",
            "Trading Position: Long\n",
            "Action: Buy NASDAQ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#without taking on the last cpi value\n",
        "\n",
        "##see how would it   perfom if close it in the next 2 hours after the reasels and open 5 minutes befoire the realease"
      ],
      "metadata": {
        "id": "EurONe1EEqAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "# Ensure 'date' column is in datetime format\n",
        "cpi['date'] = pd.to_datetime(cpi['date'])\n",
        "initial_jobless_claims['date'] = pd.to_datetime(initial_jobless_claims['date'])\n",
        "nonfarm_payrolls['date'] = pd.to_datetime(nonfarm_payrolls['date'])\n",
        "crude_oil_prices['date'] = pd.to_datetime(crude_oil_prices['date'])\n",
        "\n",
        "# Merge datasets with CPI as the base\n",
        "data = pd.merge(cpi, initial_jobless_claims, on='date', how='left')\n",
        "data = pd.merge(data, nonfarm_payrolls, on='date', how='left')\n",
        "data = pd.merge(data, crude_oil_prices, on='date', how='left')\n",
        "\n",
        "# Handle missing values\n",
        "data.ffill(inplace=True)  # Forward fill missing values\n",
        "\n",
        "# Feature Engineering: create lagged features\n",
        "data['CPI_Lag1'] = data['CPI'].shift(1)\n",
        "data['CPI_Lag2'] = data['CPI'].shift(2)\n",
        "data.dropna(inplace=True)  # Drop rows with NaN values after shifting\n",
        "\n",
        "# Define features and target\n",
        "features = ['CPI_Lag1', 'CPI_Lag2', 'Initial Jobless Claims', 'Nonfarm Payrolls', 'Crude Oil Prices']\n",
        "target = 'CPI'\n",
        "\n",
        "# Prepare training and testing data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the data to exclude the last CPI value for testing\n",
        "X_train = X.iloc[:-1]\n",
        "y_train = y.iloc[:-1]\n",
        "X_test = X.iloc[-1:]  # Use the last row for prediction\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the next CPI value (for the last row in the dataset)\n",
        "next_cpi_prediction = model.predict(X_test)\n",
        "\n",
        "# Trading Simulation\n",
        "# Get the most recent CPI value and the next release time\n",
        "latest_date = data['date'].iloc[-1]\n",
        "next_release_time = latest_date + pd.DateOffset(minutes=5)  # 5 minutes before the release\n",
        "\n",
        "# Assume price data is available and merge with the CPI data\n",
        "# This is a placeholder - you would use actual price data in practice\n",
        "# Simulating price data\n",
        "data['Price'] = np.random.randn(len(data)) * 10 + 100  # Random prices around 100\n",
        "\n",
        "# Extract relevant data for trading simulation\n",
        "latest_price = data['Price'].iloc[-1]  # Last known price\n",
        "future_price = latest_price + np.random.randn() * 2  # Simulated future price for closing (placeholder)\n",
        "\n",
        "# Trading parameters\n",
        "account_balance = 1000  # $1,000 account balance\n",
        "lot_size = 100000       # Lot size representing $100,000\n",
        "trade_lots = 1          # Number of lots traded\n",
        "spread = 0.05           # Example spread (cost to enter/exit the trade)\n",
        "\n",
        "# Decide on trading action\n",
        "current_cpi_value = data['CPI'].iloc[-1]  # Last observed CPI value\n",
        "action = 'Hold'\n",
        "if next_cpi_prediction[0] > current_cpi_value:\n",
        "    action = 'Buy NASDAQ'  # Long position\n",
        "elif next_cpi_prediction[0] < current_cpi_value:\n",
        "    action = 'Sell NASDAQ'  # Short position\n",
        "\n",
        "# Simulate closing the trade 2 hours after the release\n",
        "close_time = next_release_time + pd.DateOffset(hours=2)\n",
        "print(f\"Trading Action: {action}\")\n",
        "\n",
        "# Simulate trading performance\n",
        "if action == 'Buy NASDAQ':\n",
        "    trade_return = (future_price - latest_price) * lot_size / latest_price - spread\n",
        "elif action == 'Sell NASDAQ':\n",
        "    trade_return = (latest_price - future_price) * lot_size / latest_price - spread\n",
        "else:\n",
        "    trade_return = 0  # No change if holding\n",
        "\n",
        "# Calculate percentage return\n",
        "percentage_return = (trade_return / (lot_size * trade_lots)) * 100\n",
        "\n",
        "# Print results\n",
        "print(f\"Trade Duration: {close_time - next_release_time}\")\n",
        "print(f\"Trade Lots: {trade_lots}\")\n",
        "print(f\"Spread: {spread}\")\n",
        "print(f\"Trade Return (in dollars): {trade_return:.2f}\")\n",
        "print(f\"Percentage Return: {percentage_return:.2f}%\")\n",
        "print(f\"Predicted Next CPI Value: {next_cpi_prediction[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e46PBLnyExJt",
        "outputId": "660d431d-df72-4829-9a73-a8a4c5f88d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trading Action: Buy NASDAQ\n",
            "Trade Duration: 0 days 02:00:00\n",
            "Trade Lots: 1\n",
            "Spread: 0.05\n",
            "Trade Return (in dollars): 464.09\n",
            "Percentage Return: 0.46%\n",
            "Predicted Next CPI Value: 313.5880483097469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trading Action: Buy NASDAQ\n",
        "\n",
        "\n",
        "<hr>\n",
        "The results show that by following the models recommendation to buy NASDAQ, you achieved a profit of 464.09, which corresponds to a percentage return of 0.46% based on a $100,000 lot. The trade was executed for a duration of 2 hours and included a spread cost of 0.05. The prediction of a higher CPI value influenced the decision to go long.\n",
        "\n"
      ],
      "metadata": {
        "id": "zU-C7bNeE5aY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##for next cpi realease\n",
        "\n",
        "\n",
        "<hr>\n"
      ],
      "metadata": {
        "id": "HdCZQosU9cb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas_datareader import data as pdr\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Define the date range\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=365*2)  # Fetch data for the last 2 years\n",
        "\n",
        "# Fetch data from FRED\n",
        "cpi = pdr.get_data_fred('CPIAUCNS', start_date, end_date)\n",
        "initial_jobless_claims = pdr.get_data_fred('ICSA', start_date, end_date)\n",
        "nonfarm_payrolls = pdr.get_data_fred('PAYNSA', start_date, end_date)\n",
        "crude_oil_prices = pdr.get_data_fred('IR14200', start_date, end_date)\n",
        "\n",
        "# Merge datasets with CPI as the base\n",
        "data = cpi.join(initial_jobless_claims, how='left')\n",
        "data = data.join(nonfarm_payrolls, how='left')\n",
        "data = data.join(crude_oil_prices, how='left')\n",
        "\n",
        "# Rename columns for consistency\n",
        "data.columns = ['CPI', 'Initial Jobless Claims', 'Nonfarm Payrolls', 'Crude Oil Prices']\n",
        "\n",
        "# Handle missing values\n",
        "data.ffill(inplace=True)  # Forward fill missing values\n",
        "\n",
        "# Feature Engineering: create lagged features\n",
        "data['CPI_Lag1'] = data['CPI'].shift(1)\n",
        "data['CPI_Lag2'] = data['CPI'].shift(2)\n",
        "data.dropna(inplace=True)  # Drop rows with NaN values after shifting\n",
        "\n",
        "# Define features and target\n",
        "features = ['CPI_Lag1', 'CPI_Lag2', 'Initial Jobless Claims', 'Nonfarm Payrolls', 'Crude Oil Prices']\n",
        "target = 'CPI'\n",
        "\n",
        "# Prepare training and testing data\n",
        "X = data[features]\n",
        "y = data[target]\n",
        "\n",
        "# Split the data\n",
        "X_train = X.iloc[:-1]\n",
        "y_train = y.iloc[:-1]\n",
        "X_test = X.iloc[-1:]  # Use the last row for prediction\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the next CPI value\n",
        "next_cpi_prediction = model.predict(X_test)\n",
        "\n",
        "# Trading Simulation\n",
        "# Get the most recent CPI value and the next release time\n",
        "latest_date = data.index[-1]\n",
        "next_release_time = latest_date + pd.DateOffset(minutes=5)  # 5 minutes before the release\n",
        "\n",
        "# Simulating price data\n",
        "data['Price'] = np.random.randn(len(data)) * 10 + 100  # Random prices around 100\n",
        "\n",
        "# Extract relevant data for trading simulation\n",
        "latest_price = data['Price'].iloc[-1]  # Last known price\n",
        "future_price = latest_price + np.random.randn() * 2  # Simulated future price for closing (placeholder)\n",
        "\n",
        "# Trading parameters\n",
        "account_balance = 1000  # $1,000 account balance\n",
        "lot_size = 100000       # Lot size representing $100,000\n",
        "trade_lots = 1          # Number of lots traded\n",
        "spread = 0.05           # Example spread (cost to enter/exit the trade)\n",
        "\n",
        "# Decide on trading action\n",
        "current_cpi_value = data['CPI'].iloc[-1]  # Last observed CPI value\n",
        "action = 'Hold'\n",
        "if next_cpi_prediction[0] > current_cpi_value:\n",
        "    action = 'Buy NASDAQ'  # Long position\n",
        "elif next_cpi_prediction[0] < current_cpi_value:\n",
        "    action = 'Sell NASDAQ'  # Short position\n",
        "\n",
        "# Simulate closing the trade 2 hours after the release\n",
        "close_time = next_release_time + pd.DateOffset(hours=2)\n",
        "print(f\"Trading Action: {action}\")\n",
        "\n",
        "# Simulate trading performance\n",
        "if action == 'Buy NASDAQ':\n",
        "    trade_return = (future_price - latest_price) * lot_size / latest_price - spread\n",
        "elif action == 'Sell NASDAQ':\n",
        "    trade_return = (latest_price - future_price) * lot_size / latest_price - spread\n",
        "else:\n",
        "    trade_return = 0  # No change if holding\n",
        "\n",
        "# Calculate percentage return\n",
        "percentage_return = (trade_return / (lot_size * trade_lots)) * 100\n",
        "\n",
        "# Print results\n",
        "print(f\"Trade Duration: {close_time - next_release_time}\")\n",
        "print(f\"Trade Lots: {trade_lots}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP05l6DH9bDr",
        "outputId": "67fcaaab-44e8-4ad7-ac8c-9b98366f7afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trading Action: Buy NASDAQ\n",
            "Trade Duration: 0 days 02:00:00\n",
            "Trade Lots: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Most volatil when cpi\n",
        "\n",
        "In this section, we want to know which financial asset moves more when CPI is released to improve this strategy's profits."
      ],
      "metadata": {
        "id": "7lJ45Zsk5v-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Alpha Vantage API key\n",
        "api_key = 'RD6D8A6UOKNKZ4V7'\n",
        "\n",
        "# Define function to fetch data from Alpha Vantage\n",
        "def fetch_alpha_vantage_data(symbol, interval='daily'):\n",
        "    url = f'https://www.alphavantage.co/query'\n",
        "    params = {\n",
        "        'function': 'TIME_SERIES_DAILY' if interval == 'daily' else 'TIME_SERIES_INTRADAY',\n",
        "        'symbol': symbol,\n",
        "        'apikey': api_key\n",
        "    }\n",
        "\n",
        "    if interval == 'intraday':\n",
        "        params['interval'] = '60min'  # Example interval, can be adjusted\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status()  # Check if the request was successful\n",
        "        data = response.json()\n",
        "\n",
        "        # Handle different possible keys based on the API response\n",
        "        if 'Time Series (Daily)' in data:\n",
        "            df = pd.DataFrame(data['Time Series (Daily)']).T\n",
        "        elif 'Time Series (60min)' in data:\n",
        "            df = pd.DataFrame(data['Time Series (60min)']).T\n",
        "        else:\n",
        "            print(f\"Error fetching data for {symbol}: {data.get('Error Message', 'Unknown error')}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df = df.astype(float)\n",
        "        df.index = pd.to_datetime(df.index)\n",
        "        df.rename(columns={'4. close': 'Price'}, inplace=True)\n",
        "        return df\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request error for {symbol}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "    except ValueError as e:\n",
        "        print(f\"Data processing error for {symbol}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Define your asset lists\n",
        "stocks_assets = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'BRK.B', 'JPM', 'MA']\n",
        "forex_assets = ['EURUSD=X', 'GBPUSD=X', 'USDJPY=X', 'AUDUSD=X', 'USDCAD=X', 'USDCHF=X', 'NZDUSD=X', 'EURGBP=X', 'EURJPY=X', 'GBPJPY=X']\n",
        "\n",
        "# Define date range\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=365*2)  # Last 2 years\n",
        "\n",
        "# Fetch data for stocks and forex\n",
        "stocks_data = {asset: fetch_alpha_vantage_data(asset) for asset in stocks_assets}\n",
        "forex_data = {asset: fetch_alpha_vantage_data(asset) for asset in forex_assets}\n",
        "\n",
        "# Filter data within the desired date range\n",
        "def filter_data_by_date(data, start_date, end_date):\n",
        "    return data[(data.index >= start_date) & (data.index <= end_date)]\n",
        "\n",
        "# Calculate price changes after CPI release\n",
        "def calculate_price_changes(data, release_dates, window):\n",
        "    changes = []\n",
        "    for release_date in release_dates:\n",
        "        window_start = release_date\n",
        "        window_end = release_date + timedelta(hours=window)\n",
        "        window_data = data[(data.index >= window_start) & (data.index <= window_end)]\n",
        "        if len(window_data) > 0:\n",
        "            price_change = (window_data['Price'].iloc[-1] - window_data['Price'].iloc[0]) / window_data['Price'].iloc[0]\n",
        "            changes.append(price_change)\n",
        "    return changes\n",
        "\n",
        "# Calculate price changes\n",
        "def calculate_all_changes(data_dict, release_dates, window):\n",
        "    changes_dict = {}\n",
        "    for asset, data in data_dict.items():\n",
        "        filtered_data = filter_data_by_date(data, start_date, end_date)\n",
        "        changes = calculate_price_changes(filtered_data, release_dates, window)\n",
        "        changes_dict[asset] = changes\n",
        "    return changes_dict\n",
        "\n",
        "# Calculate price changes\n",
        "release_dates = [datetime(2023, 8, 10), datetime(2024, 2, 10)]  # Example release dates\n",
        "stocks_changes = calculate_all_changes(stocks_data, release_dates, 1)\n",
        "forex_changes = calculate_all_changes(forex_data, release_dates, 1)\n",
        "\n",
        "# Convert results to DataFrame for easy comparison\n",
        "def create_results_df(changes_dict, category):\n",
        "    results = {\n",
        "        'Asset': [],\n",
        "        'Average Change (%)': [],\n",
        "        'Volatility (%)': []\n",
        "    }\n",
        "    for asset, changes in changes_dict.items():\n",
        "        if changes:  # Avoid NaN if no changes\n",
        "            results['Asset'].append(asset)\n",
        "            results['Average Change (%)'].append(np.mean(changes) * 100)\n",
        "            results['Volatility (%)'].append(np.std(changes) * 100)\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Create DataFrames for each category\n",
        "stocks_results = create_results_df(stocks_changes, 'Stocks')\n",
        "forex_results = create_results_df(forex_changes, 'Forex')\n",
        "\n",
        "# Combine all results\n",
        "all_results = pd.concat([stocks_results, forex_results], keys=['Stocks', 'Forex'])\n",
        "print(all_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41mbwj4O6u-N",
        "outputId": "15ca696c-a422-4b82-b74a-a3fa514848c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching data for EURUSD=X: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
            "Error fetching data for GBPUSD=X: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
            "Error fetching data for USDJPY=X: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
            "Error fetching data for AUDUSD=X: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
            "Error fetching data for USDCAD=X: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
            "Error fetching data for USDCHF=X: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
            "Error fetching data for NZDUSD=X: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
            "Error fetching data for EURGBP=X: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
            "Error fetching data for EURJPY=X: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
            "Error fetching data for GBPJPY=X: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
            "Empty DataFrame\n",
            "Columns: [Asset, Average Change (%), Volatility (%)]\n",
            "Index: []\n"
          ]
        }
      ]
    }
  ]
}